{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ab8905d-4dae-4d9d-850b-bac248c4252f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Install + Imports'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"1. Install + Imports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74353782-26c6-4962-8022-21ef2d8920bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Stage 1: Train a MiniLM Retriever Using MNRL\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "import chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059ce926-c4a7-417d-8428-f61e9ea69164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MiniLM Chroma Collection (From Notebook 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77e8ec34-053c-4819-97b7-e38fefa2264a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Chroma collection: pg16_minilm\n",
      "Loaded 6865 chunks from Chroma.\n"
     ]
    }
   ],
   "source": [
    "# Must match Notebook 0 settings\n",
    "CHROMA_DIR = \"chroma_pg16_minilm\"\n",
    "COLLECTION_NAME = \"pg16_minilm\"\n",
    "\n",
    "client = chromadb.PersistentClient(path=CHROMA_DIR)\n",
    "collection = client.get_collection(COLLECTION_NAME)\n",
    "\n",
    "print(\"Loaded Chroma collection:\", COLLECTION_NAME)\n",
    "\n",
    "# Retrieve all documents\n",
    "docs = collection.get(include=[\"documents\", \"metadatas\"])\n",
    "\n",
    "documents = docs[\"documents\"]\n",
    "metadatas = docs[\"metadatas\"]\n",
    "ids = docs[\"ids\"]\n",
    "\n",
    "print(\"Loaded\", len(documents), \"chunks from Chroma.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba7692a-676c-4426-a119-7a970dfd1345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly Sample 100 Passages for MNRL Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4abab904-f599-4788-9c91-cfb8c0d97dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 100 chunks for supervised pair generation.\n"
     ]
    }
   ],
   "source": [
    "NUM_PAIRS = 100  # required by assignment guidelines\n",
    "random.seed(42)\n",
    "\n",
    "sampled_chunks = random.sample(documents, NUM_PAIRS)\n",
    "\n",
    "print(\"Sampled\", len(sampled_chunks), \"chunks for supervised pair generation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c919bba0-c1e0-45d8-8180-62d50136cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Question Generator (LLM-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b6a650e-05d8-4d36-b56f-d4b6c2a61b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-large\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "\n",
    "def generate_question(passage):\n",
    "    prompt = f\"\"\"\n",
    "    Generate a clear question whose answer is contained in the following passage.\n",
    "    Your job is to help train a retrieval model.\n",
    "    \n",
    "    Passage:\n",
    "    {passage}\n",
    "\n",
    "    Respond in JSON with:\n",
    "    {{\n",
    "        \"question\": \"...\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    response = generator(prompt, max_new_tokens=128)[0][\"generated_text\"]\n",
    "\n",
    "    # Try to extract JSON field\n",
    "    try:\n",
    "        q = response.split('\"question\":')[1].split('\"')[1]\n",
    "        return q\n",
    "    except:\n",
    "        return \"What does this passage describe?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ed1055-e216-4fb4-bb76-6e6431001f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the Training CSV (pg16_train_pairs.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc7669f2-74f5-4f75-b659-8d54a3d6c23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
      " 10%|████▏                                     | 10/100 [00:18<02:50,  1.89s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|█████████████████████████████████████████| 100/100 [01:52<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created pg16_train_pairs.csv with 100 pairs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_pairs = []\n",
    "\n",
    "for passage in tqdm(sampled_chunks):\n",
    "    q = generate_question(passage)\n",
    "    train_pairs.append({\n",
    "        \"query\": q,\n",
    "        \"positive_passage\": passage\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(train_pairs)\n",
    "df.to_csv(\"pg16_train_pairs.csv\", index=False)\n",
    "\n",
    "print(\"Created pg16_train_pairs.csv with\", len(df), \"pairs!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9809c32-5dc6-4fb0-ba12-7ba70ea12c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Training Pairs for MiniLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86efb8a9-d0d3-49f5-9904-3c9d0ec838a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>positive_passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What does this passage describe?</td>\n",
       "      <td>Internals 59.3. Foreign Data Wrapper Helper Fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does this passage describe?</td>\n",
       "      <td>sort order. Table 9.53. Array Operators Operat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does this passage describe?</td>\n",
       "      <td>SQL Syntax more expressions (separated by comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does this passage describe?</td>\n",
       "      <td>SQL Key Words Key Word PostgreSQL SQL:2023 SQL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does this passage describe?</td>\n",
       "      <td>Monitoring Database Activity Whenever VACUUM i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              query  \\\n",
       "0  What does this passage describe?   \n",
       "1  What does this passage describe?   \n",
       "2  What does this passage describe?   \n",
       "3  What does this passage describe?   \n",
       "4  What does this passage describe?   \n",
       "\n",
       "                                    positive_passage  \n",
       "0  Internals 59.3. Foreign Data Wrapper Helper Fu...  \n",
       "1  sort order. Table 9.53. Array Operators Operat...  \n",
       "2  SQL Syntax more expressions (separated by comm...  \n",
       "3  SQL Key Words Key Word PostgreSQL SQL:2023 SQL...  \n",
       "4  Monitoring Database Activity Whenever VACUUM i...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"pg16_train_pairs.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f929748-7c9f-4391-8ddf-5430cad86552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MiniLM Model for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba726161-9ebb-4c97-b781-5fb2cf643ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready!\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Move to GPU\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "# Enable gradient checkpointing to reduce VRAM usage\n",
    "model._first_module().auto_model.gradient_checkpointing_enable()\n",
    "\n",
    "print(\"Model ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4605bb56-f7b6-4574-9345-2506cd2cff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear GPU Cache Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e9dc67a-cdf1-4ae8-8b2d-0be33de92390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory cleaned.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(\"GPU memory cleaned.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ded1ccc-0ea9-4551-8ae2-078bcf6af9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df exists: True\n",
      "train_examples exists: False\n",
      "train_dataloader exists: False\n",
      "train_loss exists: False\n"
     ]
    }
   ],
   "source": [
    "print(\"df exists:\", \"df\" in globals())\n",
    "print(\"train_examples exists:\", \"train_examples\" in globals())\n",
    "print(\"train_dataloader exists:\", \"train_dataloader\" in globals())\n",
    "print(\"train_loss exists:\", \"train_loss\" in globals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4019931b-0eb0-4a18-966e-568bb9f68240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuilt training pipeline.\n",
      "Num training examples: 100\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# SAFETY REBUILD OF TRAINING DATA STRUCTURES\n",
    "# ===========================================\n",
    "\n",
    "# If df isn't loaded, load from CSV\n",
    "if \"df\" not in globals():\n",
    "    print(\"Reloading df...\")\n",
    "    df = pd.read_csv(\"pg16_train_pairs.csv\")\n",
    "\n",
    "# Rebuild training examples\n",
    "train_examples = [\n",
    "    InputExample(\n",
    "        texts=[\n",
    "            f\"query: {row['query']}\",\n",
    "            f\"passage: {row['positive_passage']}\"\n",
    "        ]\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "# Rebuild dataloader and loss function\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=4)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "print(\"Rebuilt training pipeline.\")\n",
    "print(\"Num training examples:\", len(train_examples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92693f3e-6a3e-4058-b5c1-9a6caf3d504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train MiniLM Retriever (VRAM-Safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ca7235a-ae62-4642-9d4d-5f8881cc1557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618226d61f004270b8333cd47d4a2b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 complete! Model saved to: models/pg16-minilm-mnrl\n"
     ]
    }
   ],
   "source": [
    "output_path = \"models/pg16-minilm-mnrl\"\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=1,\n",
    "    warmup_steps=int(0.1 * len(train_dataloader)),\n",
    "    show_progress_bar=True,\n",
    "    use_amp=True,          # FP16 mixed precision\n",
    "    output_path=output_path\n",
    ")\n",
    "\n",
    "print(\"Stage 1 complete! Model saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b15123-8e4b-4c9e-bb2d-adf003c3c1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
