{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f3a615-718e-42bb-902b-c36667fbf01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# STAGE 2 — Re-Embedding Chroma\n",
    "# =============================\n",
    "\n",
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54508590-065b-450f-a8c5-a6cd650afcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded fine-tuned embedding model: models/pg16-minilm-mnrl\n"
     ]
    }
   ],
   "source": [
    "# Path to fine-tuned model from Stage 1\n",
    "FINETUNED_MODEL_PATH = \"models/pg16-minilm-mnrl\"\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(FINETUNED_MODEL_PATH)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "print(\"Loaded fine-tuned embedding model:\", FINETUNED_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2beaf890-8644-4236-a536-3e24542fcd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Chroma collection: pg16_minilm\n"
     ]
    }
   ],
   "source": [
    "#2. Reconnect to Chroma\n",
    "CHROMA_DIR = \"chroma_pg16_minilm\"\n",
    "COLLECTION_NAME = \"pg16_minilm\"\n",
    "\n",
    "client = chromadb.PersistentClient(path=CHROMA_DIR)\n",
    "collection = client.get_collection(name=COLLECTION_NAME)\n",
    "\n",
    "print(\"Connected to Chroma collection:\", COLLECTION_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "494f20f1-4df7-40bf-af92-e462be4733f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from Chroma:\n",
      " • Documents: 6865\n",
      " • Example: PostgreSQL 16.11 Documentation The PostgreSQL Global Development Group\n"
     ]
    }
   ],
   "source": [
    "#3. Load ALL Stored Documents from Chroma\n",
    "# Retrieve everything from Chroma\n",
    "docs = collection.get(include=[\"documents\", \"metadatas\"])\n",
    "\n",
    "documents = docs[\"documents\"]\n",
    "metadatas = docs[\"metadatas\"]\n",
    "ids = docs[\"ids\"]   # <-- ids are always returned even if not included\n",
    "\n",
    "print(\"Loaded from Chroma:\")\n",
    "print(\" • Documents:\", len(documents))\n",
    "print(\" • Example:\", documents[0][:200])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf13e1de-e57e-4d5d-8c70-9b2594553aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Define Embedding Function Using Fine-Tuned Model\n",
    "# Batch embedding helper\n",
    "def embed_batch(texts, batch_size=64):\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i : i + batch_size]\n",
    "        emb = model.encode(\n",
    "            batch,\n",
    "            convert_to_numpy=True,\n",
    "            batch_size=batch_size,\n",
    "            show_progress_bar=False\n",
    "        )\n",
    "        all_embeddings.extend(emb)\n",
    "\n",
    "    return np.array(all_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca823c20-c52c-4e07-908a-9d77cd806503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding all documents with fine-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 108/108 [00:23<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New embedding matrix shape: (6865, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#5. Compute NEW Embeddings for All Chunks\n",
    "print(\"Encoding all documents with fine-tuned model...\")\n",
    "\n",
    "new_embeddings = embed_batch(documents, batch_size=64)\n",
    "\n",
    "print(\"New embedding matrix shape:\", new_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ddbab6-734c-49c4-942d-0c8c0bf9dd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing old embeddings...\n",
      "Old embeddings deleted.\n"
     ]
    }
   ],
   "source": [
    "#6. Clear OLD Embeddings from Chroma (Required!)\n",
    "print(\"Clearing old embeddings...\")\n",
    "\n",
    "collection.delete(ids=ids)\n",
    "\n",
    "print(\"Old embeddings deleted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1771e78-5578-4622-af12-7de9d25c8381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting new embeddings into Chroma...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 14/14 [00:13<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished re-embedding Chroma!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#7. Re-Insert Chunks with Fine-Tuned Embeddings\n",
    "print(\"Upserting new embeddings into Chroma...\")\n",
    "\n",
    "BATCH = 500\n",
    "\n",
    "for i in tqdm(range(0, len(documents), BATCH)):\n",
    "    batch_ids = ids[i : i + BATCH]\n",
    "    batch_docs = documents[i : i + BATCH]\n",
    "    batch_meta = metadatas[i : i + BATCH]\n",
    "    batch_emb = new_embeddings[i : i + BATCH]\n",
    "\n",
    "    collection.add(\n",
    "        ids=batch_ids,\n",
    "        documents=batch_docs,\n",
    "        metadatas=batch_meta,\n",
    "        embeddings=batch_emb.tolist()\n",
    "    )\n",
    "\n",
    "print(\"Finished re-embedding Chroma!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cb049e7-5545-4afe-97c5-d7fa3eda6930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Result 1 ===\n",
      "The catalog pg_index contains part of the information about indexes. The rest is mostly in pg_class . 2274\n",
      "Metadata: {'page': 2312}\n",
      "Distance: 0.6607102155685425\n",
      "\n",
      "=== Result 2 ===\n",
      "can be added to the index. Indexes can have up to 32 columns, including INCLUDE columns. (This limit can be altered when building PostgreSQL; see the file pg_config_manual.h .) 431\n",
      "Metadata: {'page': 469}\n",
      "Distance: 0.7031267881393433\n",
      "\n",
      "=== Result 3 ===\n",
      "the postgresql.conf file or on the server command line. 630\n",
      "Metadata: {'page': 668}\n",
      "Distance: 0.7253999710083008\n"
     ]
    }
   ],
   "source": [
    "#8. Test Retrieval with the Fine-Tuned Model\n",
    "query = \"How do I configure a PostgreSQL index?\"\n",
    "\n",
    "# Embed query\n",
    "q_emb = model.encode([query], convert_to_numpy=True)[0].tolist()\n",
    "\n",
    "# Query Chroma\n",
    "results = collection.query(\n",
    "    query_embeddings=[q_emb],\n",
    "    n_results=3,\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"]\n",
    ")\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"\\n=== Result {i+1} ===\")\n",
    "    print(results[\"documents\"][0][i][:300])\n",
    "    print(\"Metadata:\", results[\"metadatas\"][0][i])\n",
    "    print(\"Distance:\", results[\"distances\"][0][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63061fd4-52c5-4d61-9fa9-99309e971be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
