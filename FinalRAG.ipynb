{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349dbf16-c397-49a7-9fd9-c8d93db848be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once if needed\n",
    "# !{sys.executable} -m pip install chromadb sentence-transformers transformers accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c47154f-dffc-4d38-bbb6-807da372ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: /home/christopher_bonillajulien_22/miniconda3/envs/torch_env/bin/python\n",
      "CUDA available: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import textwrap\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from transformers import pipeline\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"Python:\", os.popen(\"which python\").read().strip())\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a648b9-51b0-4050-9ce3-b0d7ae8d3904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded retriever: models/pg16-minilm-triplet\n",
      "Connected to Chroma collection: pg16_minilm\n"
     ]
    }
   ],
   "source": [
    "#Load Chroma & Final Triplet Retriever\n",
    "# 1. Load final triplet-trained retriever\n",
    "RETRIEVER_MODEL_PATH = \"models/pg16-minilm-triplet\"\n",
    "\n",
    "retriever = SentenceTransformer(RETRIEVER_MODEL_PATH)\n",
    "retriever = SentenceTransformer(\"models/pg16-minilm-triplet\")\n",
    "retriever.to(\"cpu\")\n",
    "retriever = retriever.eval()\n",
    "print(\"Loaded retriever:\", RETRIEVER_MODEL_PATH)\n",
    "\n",
    "# 2. Connect to Chroma (must match Notebook 0/2/3)\n",
    "CHROMA_DIR = \"chroma_pg16_minilm\"\n",
    "COLLECTION_NAME = \"pg16_minilm\"\n",
    "\n",
    "client = chromadb.PersistentClient(path=CHROMA_DIR)\n",
    "collection = client.get_collection(name=COLLECTION_NAME)\n",
    "\n",
    "print(\"Connected to Chroma collection:\", COLLECTION_NAME)\n",
    "#Chroma already has embeddings from Stage 2. We’ll use the triplet model to embed the queries, and Chroma’s stored vectors for passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfaaccc6-30cb-48ad-90dd-5e1ba7f94b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded reranker on CPU: BAAI/bge-reranker-v2-m3\n"
     ]
    }
   ],
   "source": [
    "#Load Reranker (CrossEncoder)\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# CPU RERANKER (safe for all GPUs)\n",
    "RERANKER_MODEL_NAME = \"BAAI/bge-reranker-v2-m3\"\n",
    "\n",
    "reranker = CrossEncoder(RERANKER_MODEL_NAME, device=\"cpu\")  \n",
    "print(\"Loaded reranker on CPU:\", RERANKER_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0384491d-5df2-4560-9e41-39e4172d5b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded generator on CPU: Qwen/Qwen2-0.5B-Instruct\n"
     ]
    }
   ],
   "source": [
    "#Load Generator LLM\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "GENERATOR_MODEL_NAME = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=GENERATOR_MODEL_NAME,\n",
    "    device=-1,         # CPU ONLY\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "\n",
    "print(\"Loaded generator on CPU:\", GENERATOR_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c3ea11-01f5-4442-90ca-37a0bd87db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retriever Helper (Triplet Model + Chroma)\n",
    "def retrieve_with_triplet(\n",
    "    question: str,\n",
    "    k_retriever: int = 20,\n",
    "    include: list[str] = [\"documents\", \"metadatas\", \"distances\"]\n",
    "):\n",
    "    \"\"\"Use triplet model to embed query, then search Chroma by embedding.\"\"\"\n",
    "    # 1. Encode query\n",
    "    q_text = f\"query: {question}\"\n",
    "    q_emb = retriever.encode(q_text, convert_to_numpy=True)\n",
    "    \n",
    "    # 2. Query Chroma by embedding\n",
    "    result = collection.query(\n",
    "        query_embeddings=[q_emb.tolist()],\n",
    "        n_results=k_retriever,\n",
    "        include=include\n",
    "    )\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fd9abdf-f3be-4cd2-94a7-996607ce7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reranking Helper\n",
    "def rerank_results(question: str, retrieval_result, k_rerank: int = 5):\n",
    "    docs = retrieval_result[\"documents\"][0]\n",
    "    metas = retrieval_result[\"metadatas\"][0]\n",
    "    \n",
    "    # Build (query, doc) pairs for reranker\n",
    "    pairs = [(question, d) for d in docs]\n",
    "    \n",
    "    # Predict relevance scores\n",
    "    scores = reranker.predict(pairs)  # shape: [num_docs]\n",
    "    \n",
    "    # Sort by score descending\n",
    "    idx_sorted = np.argsort(scores)[::-1]\n",
    "    \n",
    "    reranked = []\n",
    "    for i in idx_sorted[:k_rerank]:\n",
    "        reranked.append({\n",
    "            \"doc\": docs[i],\n",
    "            \"meta\": metas[i],\n",
    "            \"score\": float(scores[i])\n",
    "        })\n",
    "    return reranked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea2e8f6d-0c65-403e-bec7-8537c73b5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Prompt from Context\n",
    "def build_prompt(question: str, contexts: list[dict]):\n",
    "    \"\"\"\n",
    "    contexts: list of dicts with keys: doc, meta, score\n",
    "    \"\"\"\n",
    "    context_blocks = []\n",
    "    for i, c in enumerate(contexts):\n",
    "        page = c[\"meta\"].get(\"page\", \"?\")\n",
    "        header = f\"[Doc {i+1} — page {page}, score={c['score']:.3f}]\"\n",
    "        body = textwrap.fill(c[\"doc\"], width=100)\n",
    "        context_blocks.append(header + \"\\n\" + body)\n",
    "    \n",
    "    context_text = \"\\n\\n\".join(context_blocks)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant answering questions about PostgreSQL 16 documentation.\n",
    "\n",
    "Use the CONTEXT below to answer the QUESTION. \n",
    "If the answer is not in the context, clearly say you don't know, \n",
    "and do NOT hallucinate.\n",
    "\n",
    "CONTEXT:\n",
    "{context_text}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "Answer in a clear, concise explanation. \n",
    "If relevant, refer to [Doc #] when citing specific info.\n",
    "\"\"\"\n",
    "    return prompt.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25fadb82-4f5f-45a8-8d59-bd76cc7c02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator Wrapper\n",
    "def generate_answer(prompt: str, max_new_tokens: int = 256):\n",
    "    outputs = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.3,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    # Qwen returns list of dicts with \"generated_text\"\n",
    "    text = outputs[0][\"generated_text\"]\n",
    "    # Some models echo the prompt; trim if necessary:\n",
    "    if prompt in text:\n",
    "        text = text[len(prompt):].strip()\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b83b6f3-05d9-4f61-8d66-9ca9e2ff44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full RAG Pipeline: answer_question\n",
    "def answer_question(\n",
    "    question: str,\n",
    "    k_retriever: int = 20,\n",
    "    k_rerank: int = 5,\n",
    "    k_context: int = 4\n",
    "):\n",
    "    # 1. Retrieve\n",
    "    retrieval_result = retrieve_with_triplet(question, k_retriever=k_retriever)\n",
    "    \n",
    "    # 2. Rerank\n",
    "    reranked = rerank_results(question, retrieval_result, k_rerank=k_rerank)\n",
    "    \n",
    "    # 3. Choose top-k_context for prompt\n",
    "    contexts = reranked[:k_context]\n",
    "    \n",
    "    # 4. Build prompt\n",
    "    prompt = build_prompt(question, contexts)\n",
    "    \n",
    "    # 5. Generate answer\n",
    "    answer = generate_answer(prompt)\n",
    "    \n",
    "    # 6. Pretty print result\n",
    "    print(\"QUESTION:\")\n",
    "    print(question)\n",
    "    print(\"\\nANSWER:\")\n",
    "    print(textwrap.fill(answer, width=100))\n",
    "    print(\"\\n--- SOURCES ---\")\n",
    "    for i, c in enumerate(contexts):\n",
    "        print(f\"[Doc {i+1}] page={c['meta'].get('page', '?')}, score={c['score']:.3f}\")\n",
    "        print(textwrap.fill(c[\"doc\"][:350], width=100))\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"contexts\": contexts\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "489dbf9e-ca45-492a-8d78-54023b597d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "How do I create an index in PostgreSQL?\n",
      "\n",
      "ANSWER:\n",
      "To create an index in PostgreSQL, you must specify the following:  1. The index type: B-tree, Hash,\n",
      "GiST, SP-GI-ST, GIN, BRIN, and the extension bloom.  2. The name of the index to create.  3. The\n",
      "fill factor of the index.  4. The location where the index will be stored.  5. The location where\n",
      "the index will reside in the tablespace.  6. The name of the column that will be used as the key for\n",
      "the index.  7. The name of the column that will be used as the value for the index.  8. The name of\n",
      "the column that will be used as the primary key for the index.  9. The name of the column that will\n",
      "be used as the foreign key for the index.  10. The name of the column that will be used as the index\n",
      "location for the index.  11. The name of the column that will be used as the index name for the\n",
      "index.  12. The name of the column that will be used as the index fill factor for the index.  13.\n",
      "The name of the column that will be used as the index location for the index.\n",
      "\n",
      "--- SOURCES ---\n",
      "[Doc 1] page=467, score=0.982\n",
      "Concurrently . After an index is created, the system has to keep it synchronized with the table.\n",
      "This adds overhead to data manipulation operations. Indexes can also prevent the creation of heap-\n",
      "only tuples . Therefore indexes that are seldom or never used in queries should be removed. 11.2.\n",
      "Index Types PostgreSQL provides several index types: B-tr\n",
      "--------------------------------------------------------------------------------\n",
      "[Doc 2] page=1758, score=0.981\n",
      "CREATE INDEX To create an index with non-default fill factor: CREATE UNIQUE INDEX title_idx ON films\n",
      "(title) WITH (fillfactor = 70); To create a GIN index with fast updates disabled: CREATE INDEX\n",
      "gin_idx ON documents_table USING GIN (locations) WITH (fastupdate = off); To create an index on the\n",
      "column code in the table films and have the index resi\n",
      "--------------------------------------------------------------------------------\n",
      "[Doc 3] page=1757, score=0.958\n",
      "CREATE INDEX Tip You might want to reset parallel_workers after setting it as part of tuning an\n",
      "index build. This avoids inadvertent changes to query plans, since parallel_workers affects all\n",
      "parallel table scans. While CREATE INDEX with the CONCURRENTLY option supports parallel builds\n",
      "without special restrictions, only the first table scan is actu\n",
      "--------------------------------------------------------------------------------\n",
      "[Doc 4] page=1751, score=0.931\n",
      "CREATE INDEX Parameters UNIQUE Causes the system to check for duplicate values in the table when the\n",
      "index is created (if data already exist) and each time data is added. Attempts to insert or update\n",
      "data which would result in duplicate entries will generate an error. Additional restrictions apply\n",
      "when unique indexes are applied to partitioned tabl\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Test the RAG System\n",
    "qa = answer_question(\"How do I create an index in PostgreSQL?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a3cab03-d7dc-4207-aae3-8723ce71b832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "What is the purpose of VACUUM in PostgreSQL?\n",
      "\n",
      "ANSWER:\n",
      "The purpose of VACUUM in PostgreSQL is to reclaim space occupied by dead tuples, allowing for\n",
      "efficient table scans. It also helps in maintaining a visibility map for each table, keeping track\n",
      "of which pages contain only tuples that are known to be visible to all active transactions (and all\n",
      "future transactions, until the page is again modified). Additionally, it can prevent loss of very\n",
      "old data due to transaction ID wraparound or multixact ID wrap-around. VACUUM also supports various\n",
      "options like FULL, FREEZE, VERBOSE, ANALYZE, and DISABLE_PAGE_SKIPPING, among others, depending on\n",
      "the needs of the administrator. It is essential to understand the issues discussed in the previous\n",
      "sections before implementing VACUUM.\n",
      "\n",
      "--- SOURCES ---\n",
      "[Doc 1] page=785, score=0.985\n",
      "and MRTG, but can be run standalone too. PostgreSQL is low-maintenance compared to some other\n",
      "database management systems. Nonetheless, appropriate attention to these tasks will go far towards\n",
      "ensuring a pleasant and productive experience with the system. 25.1. Routine Vacuuming PostgreSQL\n",
      "databases require periodic maintenance known as vacuuming .\n",
      "--------------------------------------------------------------------------------\n",
      "[Doc 2] page=788, score=0.975\n",
      "to date. 25.1.4. Updating the Visibility Map Vacuum maintains a visibility map for each table to\n",
      "keep track of which pages contain only tuples that are known to be visible to all active\n",
      "transactions (and all future transactions, until the page is again modified). This has two purposes.\n",
      "First, vacuum itself can skip such pages on the next run, since\n",
      "--------------------------------------------------------------------------------\n",
      "[Doc 3] page=2057, score=0.972\n",
      "VACUUM VACUUM — garbage-collect and optionally analyze a database Synopsis VACUUM [ ( option [, ...]\n",
      ") ] [ table_and_columns [, ...] ] VACUUM [ FULL ] [ FREEZE ] [ VERBOSE ] [ ANALYZE ] [\n",
      "table_and_columns [, ...] ] where option can be one of: FULL [ boolean ] FREEZE [ boolean ] VERBOSE\n",
      "[ boolean ] ANALYZE [ boolean ] DISABLE_PAGE_SKIPPING [ boolea\n",
      "--------------------------------------------------------------------------------\n",
      "[Doc 4] page=2061, score=0.941\n",
      "VACUUM shrink to occupy less disk space and allow faster table scans. VACUUM FULL will usually\n",
      "shrink the table more than a plain VACUUM would. The PARALLEL option is used only for vacuum\n",
      "purposes. If this option is specified with the ANALYZE option, it does not affect ANALYZE . VACUUM\n",
      "causes a substantial increase in I/O traffic, which might cause\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#another \n",
    "qa = answer_question(\"What is the purpose of VACUUM in PostgreSQL?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
